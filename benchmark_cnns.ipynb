{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixup_init(layer, num_layers):\n",
    "    nn.init.normal_(layer.weight, mean=0, std=np.sqrt(\n",
    "        2 / (layer.weight.shape[0] * np.prod(layer.weight.shape[2:]))) * num_layers ** (-0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normalization(channels, type=\"bn\", affine=True, one_d=False):\n",
    "    assert type in [\"bn\", \"ln\", \"in\", \"gn\", \"max\", \"none\", None]\n",
    "    if type == \"bn\":\n",
    "        if one_d:\n",
    "            return nn.BatchNorm1d(channels, affine=affine)\n",
    "        else:\n",
    "            return nn.BatchNorm2d(channels, affine=affine)\n",
    "    elif type == \"ln\":\n",
    "        if one_d:\n",
    "            return nn.LayerNorm(channels, elementwise_affine=affine)\n",
    "        else:\n",
    "            return nn.GroupNorm(1, channels, affine=affine)\n",
    "    elif type == \"in\":\n",
    "        return nn.GroupNorm(channels, channels, affine=affine)\n",
    "    elif type == \"gn\":\n",
    "        groups = max(min(32, channels//4), 1)\n",
    "        return nn.GroupNorm(groups, channels, affine=affine)\n",
    "    elif type == \"max\":\n",
    "        if not one_d:\n",
    "            return renormalize\n",
    "        else:\n",
    "            return lambda x: renormalize(x, -1)\n",
    "    elif type == \"none\" or type is None:\n",
    "        return nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio,\n",
    "                 norm_type, num_layers=1, groups=-1,\n",
    "                 drop_prob=0., bias=True):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2, 3]\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        hidden_dim = round(in_channels * expand_ratio)\n",
    "\n",
    "        if groups <= 0:\n",
    "            groups = hidden_dim\n",
    "\n",
    "        conv = nn.Conv2d\n",
    "\n",
    "        if stride != 1:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, stride, stride)\n",
    "            nn.init.normal_(self.downsample.weight, mean=0, std=\n",
    "                            np.sqrt(2 / (self.downsample.weight.shape[0] *\n",
    "                            np.prod(self.downsample.weight.shape[2:]))))\n",
    "        else:\n",
    "            self.downsample = False\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            conv1 = conv(hidden_dim, hidden_dim, 3, stride, 1, groups=groups, bias=bias)\n",
    "            conv2 = conv(hidden_dim, out_channels, 1, 1, 0, bias=bias)\n",
    "            fixup_init(conv1, num_layers)\n",
    "            fixup_init(conv2, num_layers)\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                conv1,\n",
    "                init_normalization(hidden_dim, norm_type),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                conv2,\n",
    "                init_normalization(out_channels, norm_type),\n",
    "            )\n",
    "            nn.init.constant_(self.conv[-1].weight, 0)\n",
    "        else:\n",
    "            conv1 = conv(in_channels, hidden_dim, 1, 1, 0, bias=bias)\n",
    "            conv2 = conv(hidden_dim, hidden_dim, 3, stride, 1, groups=groups, bias=bias)\n",
    "            conv3 = conv(hidden_dim, out_channels, 1, 1, 0, bias=bias)\n",
    "            fixup_init(conv1, num_layers)\n",
    "            fixup_init(conv2, num_layers)\n",
    "            fixup_init(conv3, num_layers)\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                conv1,\n",
    "                init_normalization(hidden_dim, norm_type),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                conv2,\n",
    "                init_normalization(hidden_dim, norm_type),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                conv3,\n",
    "                init_normalization(out_channels, norm_type)\n",
    "            )\n",
    "            if norm_type != \"none\":\n",
    "                nn.init.constant_(self.conv[-1].weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        else:\n",
    "            identity = x\n",
    "        if self.training and np.random.uniform() < self.drop_prob:\n",
    "            return identity\n",
    "        else:\n",
    "            return identity + self.conv(x)\n",
    "\n",
    "\n",
    "class Residual(InvertedResidual):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs, groups=1)\n",
    "\n",
    "\n",
    "class ResnetCNN(nn.Module):\n",
    "    def __init__(self, input_channels,\n",
    "                 depths=(16, 32, 64),\n",
    "                 strides=(3, 2, 2),\n",
    "                 blocks_per_group=3,\n",
    "                 norm_type=\"bn\",\n",
    "                 resblock=InvertedResidual,\n",
    "                 expand_ratio=2,):\n",
    "        super(ResnetCNN, self).__init__()\n",
    "        self.depths = [input_channels] + depths\n",
    "        self.resblock = resblock\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.blocks_per_group = blocks_per_group\n",
    "        self.layers = []\n",
    "        self.norm_type = norm_type\n",
    "        self.num_layers = self.blocks_per_group*len(depths)\n",
    "        for i in range(len(depths)):\n",
    "            self.layers.append(self._make_layer(self.depths[i],\n",
    "                                                self.depths[i+1],\n",
    "                                                strides[i],\n",
    "                                                ))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.train()\n",
    "\n",
    "    def _make_layer(self, in_channels, depth, stride,):\n",
    "\n",
    "        blocks = [self.resblock(in_channels, depth,\n",
    "                                expand_ratio=self.expand_ratio,\n",
    "                                stride=stride,\n",
    "                                norm_type=self.norm_type,\n",
    "                                num_layers=self.num_layers,)]\n",
    "\n",
    "        for i in range(1, self.blocks_per_group):\n",
    "            blocks.append(self.resblock(depth, depth,\n",
    "                                        expand_ratio=self.expand_ratio,\n",
    "                                        stride=1,\n",
    "                                        norm_type=self.norm_type,\n",
    "                                        num_layers=self.num_layers,))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    @property\n",
    "    def local_layer_depth(self):\n",
    "        return self.depths[-2]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.layers(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ResnetCNN                                     [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-1                             [1, 64, 7, 7]             --\n",
       "│    └─Sequential: 2-1                        [1, 16, 28, 28]           --\n",
       "│    │    └─InvertedResidual: 3-1             [1, 16, 28, 28]           --\n",
       "│    │    │    └─Conv2d: 4-1                  [1, 16, 28, 28]           592\n",
       "│    │    │    └─Sequential: 4-2              [1, 16, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-1             [1, 8, 84, 84]            40\n",
       "│    │    │    │    └─BatchNorm2d: 5-2        [1, 8, 84, 84]            16\n",
       "│    │    │    │    └─ReLU: 5-3               [1, 8, 84, 84]            --\n",
       "│    │    │    │    └─Conv2d: 5-4             [1, 8, 28, 28]            80\n",
       "│    │    │    │    └─BatchNorm2d: 5-5        [1, 8, 28, 28]            16\n",
       "│    │    │    │    └─ReLU: 5-6               [1, 8, 28, 28]            --\n",
       "│    │    │    │    └─Conv2d: 5-7             [1, 16, 28, 28]           144\n",
       "│    │    │    │    └─BatchNorm2d: 5-8        [1, 16, 28, 28]           32\n",
       "│    │    └─InvertedResidual: 3-2             [1, 16, 28, 28]           --\n",
       "│    │    │    └─Sequential: 4-3              [1, 16, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-9             [1, 32, 28, 28]           544\n",
       "│    │    │    │    └─BatchNorm2d: 5-10       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-11              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-12            [1, 32, 28, 28]           320\n",
       "│    │    │    │    └─BatchNorm2d: 5-13       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-14              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-15            [1, 16, 28, 28]           528\n",
       "│    │    │    │    └─BatchNorm2d: 5-16       [1, 16, 28, 28]           32\n",
       "│    │    └─InvertedResidual: 3-3             [1, 16, 28, 28]           --\n",
       "│    │    │    └─Sequential: 4-4              [1, 16, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-17            [1, 32, 28, 28]           544\n",
       "│    │    │    │    └─BatchNorm2d: 5-18       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-19              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-20            [1, 32, 28, 28]           320\n",
       "│    │    │    │    └─BatchNorm2d: 5-21       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-22              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-23            [1, 16, 28, 28]           528\n",
       "│    │    │    │    └─BatchNorm2d: 5-24       [1, 16, 28, 28]           32\n",
       "│    └─Sequential: 2-2                        [1, 32, 14, 14]           --\n",
       "│    │    └─InvertedResidual: 3-4             [1, 32, 14, 14]           --\n",
       "│    │    │    └─Conv2d: 4-5                  [1, 32, 14, 14]           2,080\n",
       "│    │    │    └─Sequential: 4-6              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-25            [1, 32, 28, 28]           544\n",
       "│    │    │    │    └─BatchNorm2d: 5-26       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-27              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-28            [1, 32, 14, 14]           320\n",
       "│    │    │    │    └─BatchNorm2d: 5-29       [1, 32, 14, 14]           64\n",
       "│    │    │    │    └─ReLU: 5-30              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-31            [1, 32, 14, 14]           1,056\n",
       "│    │    │    │    └─BatchNorm2d: 5-32       [1, 32, 14, 14]           64\n",
       "│    │    └─InvertedResidual: 3-5             [1, 32, 14, 14]           --\n",
       "│    │    │    └─Sequential: 4-7              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-33            [1, 64, 14, 14]           2,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-34       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-35              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-36            [1, 64, 14, 14]           640\n",
       "│    │    │    │    └─BatchNorm2d: 5-37       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-38              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-39            [1, 32, 14, 14]           2,080\n",
       "│    │    │    │    └─BatchNorm2d: 5-40       [1, 32, 14, 14]           64\n",
       "│    │    └─InvertedResidual: 3-6             [1, 32, 14, 14]           --\n",
       "│    │    │    └─Sequential: 4-8              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-41            [1, 64, 14, 14]           2,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-42       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-43              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-44            [1, 64, 14, 14]           640\n",
       "│    │    │    │    └─BatchNorm2d: 5-45       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-46              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-47            [1, 32, 14, 14]           2,080\n",
       "│    │    │    │    └─BatchNorm2d: 5-48       [1, 32, 14, 14]           64\n",
       "│    └─Sequential: 2-3                        [1, 64, 7, 7]             --\n",
       "│    │    └─InvertedResidual: 3-7             [1, 64, 7, 7]             --\n",
       "│    │    │    └─Conv2d: 4-9                  [1, 64, 7, 7]             8,256\n",
       "│    │    │    └─Sequential: 4-10             [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-49            [1, 64, 14, 14]           2,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-50       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-51              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-52            [1, 64, 7, 7]             640\n",
       "│    │    │    │    └─BatchNorm2d: 5-53       [1, 64, 7, 7]             128\n",
       "│    │    │    │    └─ReLU: 5-54              [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-55            [1, 64, 7, 7]             4,160\n",
       "│    │    │    │    └─BatchNorm2d: 5-56       [1, 64, 7, 7]             128\n",
       "│    │    └─InvertedResidual: 3-8             [1, 64, 7, 7]             --\n",
       "│    │    │    └─Sequential: 4-11             [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-57            [1, 128, 7, 7]            8,320\n",
       "│    │    │    │    └─BatchNorm2d: 5-58       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-59              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-60            [1, 128, 7, 7]            1,280\n",
       "│    │    │    │    └─BatchNorm2d: 5-61       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-62              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-63            [1, 64, 7, 7]             8,256\n",
       "│    │    │    │    └─BatchNorm2d: 5-64       [1, 64, 7, 7]             128\n",
       "│    │    └─InvertedResidual: 3-9             [1, 64, 7, 7]             --\n",
       "│    │    │    └─Sequential: 4-12             [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-65            [1, 128, 7, 7]            8,320\n",
       "│    │    │    │    └─BatchNorm2d: 5-66       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-67              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-68            [1, 128, 7, 7]            1,280\n",
       "│    │    │    │    └─BatchNorm2d: 5-69       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-70              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-71            [1, 64, 7, 7]             8,256\n",
       "│    │    │    │    └─BatchNorm2d: 5-72       [1, 64, 7, 7]             128\n",
       "===============================================================================================\n",
       "Total params: 71,064\n",
       "Trainable params: 71,064\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.91\n",
       "===============================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 5.80\n",
       "Params size (MB): 0.28\n",
       "Estimated Total Size (MB): 6.19\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResnetCNN(4, depths=[16, 32, 64], strides=(3, 2, 2), blocks_per_group=3, norm_type=\"bn\", resblock=InvertedResidual, expand_ratio=2,)\n",
    "model(torch.randn(1, 4, 84,84))\n",
    "torchinfo.summary(model, input_data=torch.randn(1, 4, 84,84), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetCNN(\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (downsample): Conv2d(4, 16, kernel_size=(3, 3), stride=(3, 3))\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1), groups=8)\n",
       "          (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (downsample): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (downsample): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.networks import ConvNeXtImpala, ImpalaCNNLarge, ImpalaNeXtCNNLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeXtImpala(4, 12, nn.Linear, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1186, -0.0862,  0.0036, -0.0597, -0.0614, -0.0916, -0.0497, -0.0922,\n",
       "          0.0408, -0.0544, -0.0239, -0.0627]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 4, 84,84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ConvNeXtImpala                                     [1, 12]                   --\n",
       "├─ConvNeXt: 1-1                                    [1, 128, 7, 7]            --\n",
       "│    └─Sequential: 2-1                             [1, 32, 28, 28]           --\n",
       "│    │    └─Conv2d: 3-1                            [1, 32, 28, 28]           1,184\n",
       "│    │    └─LayerNorm2d: 3-2                       [1, 32, 28, 28]           64\n",
       "│    └─Sequential: 2-2                             [1, 128, 7, 7]            --\n",
       "│    │    └─ConvNeXtStage: 3-3                     [1, 32, 28, 28]           --\n",
       "│    │    │    └─Identity: 4-1                     [1, 32, 28, 28]           --\n",
       "│    │    │    └─Sequential: 4-2                   [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-1           [1, 32, 28, 28]           32\n",
       "│    │    │    │    │    └─Conv2d: 6-1             [1, 32, 28, 28]           1,600\n",
       "│    │    │    │    │    └─LayerNorm: 6-2          [1, 28, 28, 32]           64\n",
       "│    │    │    │    │    └─Mlp: 6-3                [1, 28, 28, 32]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-1        [1, 28, 28, 128]          4,224\n",
       "│    │    │    │    │    │    └─GELU: 7-2          [1, 28, 28, 128]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-3       [1, 28, 28, 128]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-4        [1, 28, 28, 32]           4,128\n",
       "│    │    │    │    │    │    └─Dropout: 7-5       [1, 28, 28, 32]           --\n",
       "│    │    │    │    │    └─Identity: 6-4           [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-2           [1, 32, 28, 28]           32\n",
       "│    │    │    │    │    └─Conv2d: 6-5             [1, 32, 28, 28]           1,600\n",
       "│    │    │    │    │    └─LayerNorm: 6-6          [1, 28, 28, 32]           64\n",
       "│    │    │    │    │    └─Mlp: 6-7                [1, 28, 28, 32]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-6        [1, 28, 28, 128]          4,224\n",
       "│    │    │    │    │    │    └─GELU: 7-7          [1, 28, 28, 128]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-8       [1, 28, 28, 128]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-9        [1, 28, 28, 32]           4,128\n",
       "│    │    │    │    │    │    └─Dropout: 7-10      [1, 28, 28, 32]           --\n",
       "│    │    │    │    │    └─Identity: 6-8           [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-3           [1, 32, 28, 28]           32\n",
       "│    │    │    │    │    └─Conv2d: 6-9             [1, 32, 28, 28]           1,600\n",
       "│    │    │    │    │    └─LayerNorm: 6-10         [1, 28, 28, 32]           64\n",
       "│    │    │    │    │    └─Mlp: 6-11               [1, 28, 28, 32]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-11       [1, 28, 28, 128]          4,224\n",
       "│    │    │    │    │    │    └─GELU: 7-12         [1, 28, 28, 128]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-13      [1, 28, 28, 128]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-14       [1, 28, 28, 32]           4,128\n",
       "│    │    │    │    │    │    └─Dropout: 7-15      [1, 28, 28, 32]           --\n",
       "│    │    │    │    │    └─Identity: 6-12          [1, 32, 28, 28]           --\n",
       "│    │    └─ConvNeXtStage: 3-4                     [1, 64, 14, 14]           --\n",
       "│    │    │    └─Sequential: 4-3                   [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─LayerNorm2d: 5-4             [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─Conv2d: 5-5                  [1, 64, 14, 14]           8,256\n",
       "│    │    │    └─Sequential: 4-4                   [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-6           [1, 64, 14, 14]           64\n",
       "│    │    │    │    │    └─Conv2d: 6-13            [1, 64, 14, 14]           3,200\n",
       "│    │    │    │    │    └─LayerNorm: 6-14         [1, 14, 14, 64]           128\n",
       "│    │    │    │    │    └─Mlp: 6-15               [1, 14, 14, 64]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-16       [1, 14, 14, 256]          16,640\n",
       "│    │    │    │    │    │    └─GELU: 7-17         [1, 14, 14, 256]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-18      [1, 14, 14, 256]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-19       [1, 14, 14, 64]           16,448\n",
       "│    │    │    │    │    │    └─Dropout: 7-20      [1, 14, 14, 64]           --\n",
       "│    │    │    │    │    └─Identity: 6-16          [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-7           [1, 64, 14, 14]           64\n",
       "│    │    │    │    │    └─Conv2d: 6-17            [1, 64, 14, 14]           3,200\n",
       "│    │    │    │    │    └─LayerNorm: 6-18         [1, 14, 14, 64]           128\n",
       "│    │    │    │    │    └─Mlp: 6-19               [1, 14, 14, 64]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-21       [1, 14, 14, 256]          16,640\n",
       "│    │    │    │    │    │    └─GELU: 7-22         [1, 14, 14, 256]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-23      [1, 14, 14, 256]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-24       [1, 14, 14, 64]           16,448\n",
       "│    │    │    │    │    │    └─Dropout: 7-25      [1, 14, 14, 64]           --\n",
       "│    │    │    │    │    └─Identity: 6-20          [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-8           [1, 64, 14, 14]           64\n",
       "│    │    │    │    │    └─Conv2d: 6-21            [1, 64, 14, 14]           3,200\n",
       "│    │    │    │    │    └─LayerNorm: 6-22         [1, 14, 14, 64]           128\n",
       "│    │    │    │    │    └─Mlp: 6-23               [1, 14, 14, 64]           --\n",
       "│    │    │    │    │    │    └─Linear: 7-26       [1, 14, 14, 256]          16,640\n",
       "│    │    │    │    │    │    └─GELU: 7-27         [1, 14, 14, 256]          --\n",
       "│    │    │    │    │    │    └─Dropout: 7-28      [1, 14, 14, 256]          --\n",
       "│    │    │    │    │    │    └─Linear: 7-29       [1, 14, 14, 64]           16,448\n",
       "│    │    │    │    │    │    └─Dropout: 7-30      [1, 14, 14, 64]           --\n",
       "│    │    │    │    │    └─Identity: 6-24          [1, 64, 14, 14]           --\n",
       "│    │    └─ConvNeXtStage: 3-5                     [1, 128, 7, 7]            --\n",
       "│    │    │    └─Sequential: 4-5                   [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─LayerNorm2d: 5-9             [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─Conv2d: 5-10                 [1, 128, 7, 7]            32,896\n",
       "│    │    │    └─Sequential: 4-6                   [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-11          [1, 128, 7, 7]            128\n",
       "│    │    │    │    │    └─Conv2d: 6-25            [1, 128, 7, 7]            6,400\n",
       "│    │    │    │    │    └─LayerNorm: 6-26         [1, 7, 7, 128]            256\n",
       "│    │    │    │    │    └─Mlp: 6-27               [1, 7, 7, 128]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-31       [1, 7, 7, 512]            66,048\n",
       "│    │    │    │    │    │    └─GELU: 7-32         [1, 7, 7, 512]            --\n",
       "│    │    │    │    │    │    └─Dropout: 7-33      [1, 7, 7, 512]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-34       [1, 7, 7, 128]            65,664\n",
       "│    │    │    │    │    │    └─Dropout: 7-35      [1, 7, 7, 128]            --\n",
       "│    │    │    │    │    └─Identity: 6-28          [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-12          [1, 128, 7, 7]            128\n",
       "│    │    │    │    │    └─Conv2d: 6-29            [1, 128, 7, 7]            6,400\n",
       "│    │    │    │    │    └─LayerNorm: 6-30         [1, 7, 7, 128]            256\n",
       "│    │    │    │    │    └─Mlp: 6-31               [1, 7, 7, 128]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-36       [1, 7, 7, 512]            66,048\n",
       "│    │    │    │    │    │    └─GELU: 7-37         [1, 7, 7, 512]            --\n",
       "│    │    │    │    │    │    └─Dropout: 7-38      [1, 7, 7, 512]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-39       [1, 7, 7, 128]            65,664\n",
       "│    │    │    │    │    │    └─Dropout: 7-40      [1, 7, 7, 128]            --\n",
       "│    │    │    │    │    └─Identity: 6-32          [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─ConvNeXtBlock: 5-13          [1, 128, 7, 7]            128\n",
       "│    │    │    │    │    └─Conv2d: 6-33            [1, 128, 7, 7]            6,400\n",
       "│    │    │    │    │    └─LayerNorm: 6-34         [1, 7, 7, 128]            256\n",
       "│    │    │    │    │    └─Mlp: 6-35               [1, 7, 7, 128]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-41       [1, 7, 7, 512]            66,048\n",
       "│    │    │    │    │    │    └─GELU: 7-42         [1, 7, 7, 512]            --\n",
       "│    │    │    │    │    │    └─Dropout: 7-43      [1, 7, 7, 512]            --\n",
       "│    │    │    │    │    │    └─Linear: 7-44       [1, 7, 7, 128]            65,664\n",
       "│    │    │    │    │    │    └─Dropout: 7-45      [1, 7, 7, 128]            --\n",
       "│    │    │    │    │    └─Identity: 6-36          [1, 128, 7, 7]            --\n",
       "│    └─Identity: 2-3                               [1, 128, 7, 7]            --\n",
       "│    └─Sequential: 2-4                             --                        --\n",
       "│    │    └─Identity: 3-6                          [1, 128, 7, 7]            --\n",
       "│    │    └─Identity: 3-7                          [1, 128, 7, 7]            --\n",
       "│    │    └─Identity: 3-8                          [1, 128, 7, 7]            --\n",
       "│    │    └─Dropout: 3-9                           [1, 128, 7, 7]            --\n",
       "│    │    └─Identity: 3-10                         [1, 128, 7, 7]            --\n",
       "├─Dueling: 1-2                                     [1, 12]                   --\n",
       "│    └─Flatten: 2-5                                [1, 6272]                 --\n",
       "│    └─Sequential: 2-6                             [1, 12]                   --\n",
       "│    │    └─Linear: 3-11                           [1, 512]                  3,211,776\n",
       "│    │    └─GELU: 3-12                             [1, 512]                  --\n",
       "│    │    └─Linear: 3-13                           [1, 12]                   6,156\n",
       "│    └─Sequential: 2-7                             [1, 1]                    --\n",
       "│    │    └─Linear: 3-14                           [1, 512]                  3,211,776\n",
       "│    │    └─GELU: 3-15                             [1, 512]                  --\n",
       "│    │    └─Linear: 3-16                           [1, 1]                    513\n",
       "====================================================================================================\n",
       "Total params: 7,027,885\n",
       "Trainable params: 7,027,885\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 17.70\n",
       "====================================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 8.24\n",
       "Params size (MB): 28.11\n",
       "Estimated Total Size (MB): 36.46\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b\"\\xa3\\x0b\\x8cj\\x94\\x06?\\xcc\\n\\xd2\\xcdTf\\x82@\\xa2C\\xa6\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\"]\n",
      "Bad pipe message: %s [b'\\xf4Kf\"d\\x9d\\xd5a\\xb5\\x84t\\x97%H\\xa9ylU\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0\\'\\x00g\\x00@\\xc0r']\n",
      "Bad pipe message: %s [b'\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\\x01\\x03\\x02\\x02\\x02\\x04\\x02\\x05']\n",
      "Bad pipe message: %s [b'\\x02']\n",
      "Bad pipe message: %s [b'\"\\xa1\\xfc^P\\x0fI\\x9d\\xf2\\xa0P\\xe1=\\'\"\\xd1B\\x85\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00', b'\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01']\n",
      "Bad pipe message: %s [b'\\n\\xb5:V\\x05\\xea\\x95\\xb9\\xde\\x97\\xe4\\xcb\\x9d\\x1aT\\xfb\\xda\\xd0\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00']\n",
      "Bad pipe message: %s [b'\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06']\n",
      "Bad pipe message: %s [b\"\\xb0\\xe5\\x1bJ\\x11\\x88\\xaa\\x13\\x87&O\\xc1\\x89\\xcd'u\\x8cY\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\"]\n",
      "Bad pipe message: %s [b\"\\x8e\\xd1g\\xf2E\\x7f\\xcc\\x89k\\x85\\xbc\\x13;D\\xe53\\x93\\xf2\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\", b'\\x01\\x05', b'\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b\"\\xae\\xce\\x04m\\x1cJG\\x9b\\xea\\xe6\\xb6Q\\xddV\\x9b\\x99\\x06*\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\"]\n"
     ]
    }
   ],
   "source": [
    "torchinfo.summary(model, input_data=torch.randn(1, 4, 84,84), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ImpalaCNNLarge                           [1, 12]                   --\n",
       "├─Sequential: 1-1                        [1, 64, 11, 11]           --\n",
       "│    └─ImpalaCNNBlock: 2-1               [1, 32, 42, 42]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 32, 84, 84]           1,184\n",
       "│    │    └─MaxPool2d: 3-2               [1, 32, 42, 42]           --\n",
       "│    │    └─ImpalaCNNResidual: 3-3       [1, 32, 42, 42]           --\n",
       "│    │    │    └─ReLU: 4-1               [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-2             [1, 32, 42, 42]           9,248\n",
       "│    │    │    └─ReLU: 4-3               [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-4             [1, 32, 42, 42]           9,248\n",
       "│    │    └─ImpalaCNNResidual: 3-4       [1, 32, 42, 42]           --\n",
       "│    │    │    └─ReLU: 4-5               [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-6             [1, 32, 42, 42]           9,248\n",
       "│    │    │    └─ReLU: 4-7               [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-8             [1, 32, 42, 42]           9,248\n",
       "│    └─ImpalaCNNBlock: 2-2               [1, 64, 21, 21]           --\n",
       "│    │    └─Conv2d: 3-5                  [1, 64, 42, 42]           18,496\n",
       "│    │    └─MaxPool2d: 3-6               [1, 64, 21, 21]           --\n",
       "│    │    └─ImpalaCNNResidual: 3-7       [1, 64, 21, 21]           --\n",
       "│    │    │    └─ReLU: 4-9               [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-10            [1, 64, 21, 21]           36,928\n",
       "│    │    │    └─ReLU: 4-11              [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-12            [1, 64, 21, 21]           36,928\n",
       "│    │    └─ImpalaCNNResidual: 3-8       [1, 64, 21, 21]           --\n",
       "│    │    │    └─ReLU: 4-13              [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-14            [1, 64, 21, 21]           36,928\n",
       "│    │    │    └─ReLU: 4-15              [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-16            [1, 64, 21, 21]           36,928\n",
       "│    └─ImpalaCNNBlock: 2-3               [1, 64, 11, 11]           --\n",
       "│    │    └─Conv2d: 3-9                  [1, 64, 21, 21]           36,928\n",
       "│    │    └─MaxPool2d: 3-10              [1, 64, 11, 11]           --\n",
       "│    │    └─ImpalaCNNResidual: 3-11      [1, 64, 11, 11]           --\n",
       "│    │    │    └─ReLU: 4-17              [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-18            [1, 64, 11, 11]           36,928\n",
       "│    │    │    └─ReLU: 4-19              [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-20            [1, 64, 11, 11]           36,928\n",
       "│    │    └─ImpalaCNNResidual: 3-12      [1, 64, 11, 11]           --\n",
       "│    │    │    └─ReLU: 4-21              [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-22            [1, 64, 11, 11]           36,928\n",
       "│    │    │    └─ReLU: 4-23              [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-24            [1, 64, 11, 11]           36,928\n",
       "│    └─ReLU: 2-4                         [1, 64, 11, 11]           --\n",
       "├─AdaptiveMaxPool2d: 1-2                 [1, 64, 8, 8]             --\n",
       "├─Dueling: 1-3                           [1, 12]                   --\n",
       "│    └─Flatten: 2-5                      [1, 4096]                 --\n",
       "│    └─Sequential: 2-6                   [1, 12]                   --\n",
       "│    │    └─Linear: 3-13                 [1, 256]                  1,048,832\n",
       "│    │    └─ReLU: 3-14                   [1, 256]                  --\n",
       "│    │    └─Linear: 3-15                 [1, 12]                   3,084\n",
       "│    └─Sequential: 2-7                   [1, 1]                    --\n",
       "│    │    └─Linear: 3-16                 [1, 256]                  1,048,832\n",
       "│    │    └─ReLU: 3-17                   [1, 256]                  --\n",
       "│    │    └─Linear: 3-18                 [1, 1]                    257\n",
       "==========================================================================================\n",
       "Total params: 2,490,029\n",
       "Trainable params: 2,490,029\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 207.64\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 5.90\n",
       "Params size (MB): 9.96\n",
       "Estimated Total Size (MB): 15.97\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImpalaCNNLarge(4, 12, nn.Linear, 2)\n",
    "torchinfo.summary(model, input_data=torch.randn(1, 4, 84,84), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both\n",
      "both\n",
      "both\n",
      "both\n",
      "both\n",
      "both\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ImpalaNeXtCNNLarge                            [1, 12]                   --\n",
       "├─ImpalaNeXtDownsample: 1-1                   [1, 32, 42, 42]           --\n",
       "│    └─Identity: 2-1                          [1, 4, 84, 84]            --\n",
       "│    └─Conv2d: 2-2                            [1, 32, 84, 84]           6,304\n",
       "│    └─MaxPool2d: 2-3                         [1, 32, 42, 42]           --\n",
       "├─Sequential: 1-2                             [1, 64, 11, 11]           --\n",
       "│    └─ImpalaNeXtCNNBlock: 2-4                [1, 32, 42, 42]           --\n",
       "│    │    └─ImpalaNeXtCNNResidual: 3-1        [1, 32, 42, 42]           --\n",
       "│    │    │    └─GELU: 4-1                    [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-2                  [1, 32, 42, 42]           50,208\n",
       "│    │    │    └─Identity: 4-3                [1, 32, 42, 42]           --\n",
       "│    │    │    └─GELU: 4-4                    [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-5                  [1, 32, 42, 42]           50,208\n",
       "│    │    └─ImpalaNeXtCNNResidual: 3-2        [1, 32, 42, 42]           --\n",
       "│    │    │    └─GELU: 4-6                    [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-7                  [1, 32, 42, 42]           50,208\n",
       "│    │    │    └─Identity: 4-8                [1, 32, 42, 42]           --\n",
       "│    │    │    └─GELU: 4-9                    [1, 32, 42, 42]           --\n",
       "│    │    │    └─Conv2d: 4-10                 [1, 32, 42, 42]           50,208\n",
       "│    └─ImpalaNeXtDownsample: 2-5              [1, 64, 21, 21]           --\n",
       "│    │    └─Identity: 3-3                     [1, 32, 42, 42]           --\n",
       "│    │    └─Conv2d: 3-4                       [1, 64, 42, 42]           100,416\n",
       "│    │    └─MaxPool2d: 3-5                    [1, 64, 21, 21]           --\n",
       "│    └─ImpalaNeXtCNNBlock: 2-6                [1, 64, 21, 21]           --\n",
       "│    │    └─ImpalaNeXtCNNResidual: 3-6        [1, 64, 21, 21]           --\n",
       "│    │    │    └─GELU: 4-11                   [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-12                 [1, 64, 21, 21]           200,768\n",
       "│    │    │    └─Identity: 4-13               [1, 64, 21, 21]           --\n",
       "│    │    │    └─GELU: 4-14                   [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-15                 [1, 64, 21, 21]           200,768\n",
       "│    │    └─ImpalaNeXtCNNResidual: 3-7        [1, 64, 21, 21]           --\n",
       "│    │    │    └─GELU: 4-16                   [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-17                 [1, 64, 21, 21]           200,768\n",
       "│    │    │    └─Identity: 4-18               [1, 64, 21, 21]           --\n",
       "│    │    │    └─GELU: 4-19                   [1, 64, 21, 21]           --\n",
       "│    │    │    └─Conv2d: 4-20                 [1, 64, 21, 21]           200,768\n",
       "│    └─ImpalaNeXtDownsample: 2-7              [1, 64, 11, 11]           --\n",
       "│    │    └─Identity: 3-8                     [1, 64, 21, 21]           --\n",
       "│    │    └─Conv2d: 3-9                       [1, 64, 21, 21]           200,768\n",
       "│    │    └─MaxPool2d: 3-10                   [1, 64, 11, 11]           --\n",
       "│    └─ImpalaNeXtCNNBlock: 2-8                [1, 64, 11, 11]           --\n",
       "│    │    └─ImpalaNeXtCNNResidual: 3-11       [1, 64, 11, 11]           --\n",
       "│    │    │    └─GELU: 4-21                   [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-22                 [1, 64, 11, 11]           200,768\n",
       "│    │    │    └─Identity: 4-23               [1, 64, 11, 11]           --\n",
       "│    │    │    └─GELU: 4-24                   [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-25                 [1, 64, 11, 11]           200,768\n",
       "│    │    └─ImpalaNeXtCNNResidual: 3-12       [1, 64, 11, 11]           --\n",
       "│    │    │    └─GELU: 4-26                   [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-27                 [1, 64, 11, 11]           200,768\n",
       "│    │    │    └─Identity: 4-28               [1, 64, 11, 11]           --\n",
       "│    │    │    └─GELU: 4-29                   [1, 64, 11, 11]           --\n",
       "│    │    │    └─Conv2d: 4-30                 [1, 64, 11, 11]           200,768\n",
       "│    └─GELU: 2-9                              [1, 64, 11, 11]           --\n",
       "├─AdaptiveMaxPool2d: 1-3                      [1, 64, 8, 8]             --\n",
       "├─Dueling: 1-4                                [1, 12]                   --\n",
       "│    └─Flatten: 2-10                          [1, 4096]                 --\n",
       "│    └─Sequential: 2-11                       [1, 12]                   --\n",
       "│    │    └─Linear: 3-13                      [1, 256]                  1,048,832\n",
       "│    │    └─GELU: 3-14                        [1, 256]                  --\n",
       "│    │    └─Linear: 3-15                      [1, 12]                   3,084\n",
       "│    └─Sequential: 2-12                       [1, 1]                    --\n",
       "│    │    └─Linear: 3-16                      [1, 256]                  1,048,832\n",
       "│    │    └─GELU: 3-17                        [1, 256]                  --\n",
       "│    │    └─Linear: 3-18                      [1, 1]                    257\n",
       "===============================================================================================\n",
       "Total params: 4,215,469\n",
       "Trainable params: 4,215,469\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.12\n",
       "===============================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 5.90\n",
       "Params size (MB): 16.86\n",
       "Estimated Total Size (MB): 22.87\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImpalaNeXtCNNLarge(in_depth=4, actions=12, linear_layer=nn.Linear, model_size=2, spectral_norm=False, stem='orig',\n",
    "                        convnext_downsampling=False, layer_norm=False, activation_pos='both')\n",
    "torchinfo.summary(model, input_data=torch.randn(1, 4, 84,84), depth=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
