{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixup_init(layer, num_layers):\n",
    "    nn.init.normal_(layer.weight, mean=0, std=np.sqrt(\n",
    "        2 / (layer.weight.shape[0] * np.prod(layer.weight.shape[2:]))) * num_layers ** (-0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normalization(channels, type=\"bn\", affine=True, one_d=False):\n",
    "    assert type in [\"bn\", \"ln\", \"in\", \"gn\", \"max\", \"none\", None]\n",
    "    if type == \"bn\":\n",
    "        if one_d:\n",
    "            return nn.BatchNorm1d(channels, affine=affine)\n",
    "        else:\n",
    "            return nn.BatchNorm2d(channels, affine=affine)\n",
    "    elif type == \"ln\":\n",
    "        if one_d:\n",
    "            return nn.LayerNorm(channels, elementwise_affine=affine)\n",
    "        else:\n",
    "            return nn.GroupNorm(1, channels, affine=affine)\n",
    "    elif type == \"in\":\n",
    "        return nn.GroupNorm(channels, channels, affine=affine)\n",
    "    elif type == \"gn\":\n",
    "        groups = max(min(32, channels//4), 1)\n",
    "        return nn.GroupNorm(groups, channels, affine=affine)\n",
    "    elif type == \"max\":\n",
    "        if not one_d:\n",
    "            return renormalize\n",
    "        else:\n",
    "            return lambda x: renormalize(x, -1)\n",
    "    elif type == \"none\" or type is None:\n",
    "        return nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio,\n",
    "                 norm_type, num_layers=1, groups=-1,\n",
    "                 drop_prob=0., bias=True):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2, 3]\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        hidden_dim = round(in_channels * expand_ratio)\n",
    "\n",
    "        if groups <= 0:\n",
    "            groups = hidden_dim\n",
    "\n",
    "        conv = nn.Conv2d\n",
    "\n",
    "        if stride != 1:\n",
    "            self.downsample = nn.Conv2d(in_channels, out_channels, stride, stride)\n",
    "            nn.init.normal_(self.downsample.weight, mean=0, std=\n",
    "                            np.sqrt(2 / (self.downsample.weight.shape[0] *\n",
    "                            np.prod(self.downsample.weight.shape[2:]))))\n",
    "        else:\n",
    "            self.downsample = False\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            conv1 = conv(hidden_dim, hidden_dim, 3, stride, 1, groups=groups, bias=bias)\n",
    "            conv2 = conv(hidden_dim, out_channels, 1, 1, 0, bias=bias)\n",
    "            fixup_init(conv1, num_layers)\n",
    "            fixup_init(conv2, num_layers)\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                conv1,\n",
    "                init_normalization(hidden_dim, norm_type),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                conv2,\n",
    "                init_normalization(out_channels, norm_type),\n",
    "            )\n",
    "            nn.init.constant_(self.conv[-1].weight, 0)\n",
    "        else:\n",
    "            conv1 = conv(in_channels, hidden_dim, 1, 1, 0, bias=bias)\n",
    "            conv2 = conv(hidden_dim, hidden_dim, 3, stride, 1, groups=groups, bias=bias)\n",
    "            conv3 = conv(hidden_dim, out_channels, 1, 1, 0, bias=bias)\n",
    "            fixup_init(conv1, num_layers)\n",
    "            fixup_init(conv2, num_layers)\n",
    "            fixup_init(conv3, num_layers)\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                conv1,\n",
    "                init_normalization(hidden_dim, norm_type),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                conv2,\n",
    "                init_normalization(hidden_dim, norm_type),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                conv3,\n",
    "                init_normalization(out_channels, norm_type)\n",
    "            )\n",
    "            if norm_type != \"none\":\n",
    "                nn.init.constant_(self.conv[-1].weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        else:\n",
    "            identity = x\n",
    "        if self.training and np.random.uniform() < self.drop_prob:\n",
    "            return identity\n",
    "        else:\n",
    "            return identity + self.conv(x)\n",
    "\n",
    "\n",
    "class Residual(InvertedResidual):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs, groups=1)\n",
    "\n",
    "\n",
    "class ResnetCNN(nn.Module):\n",
    "    def __init__(self, input_channels,\n",
    "                 depths=(16, 32, 64),\n",
    "                 strides=(3, 2, 2),\n",
    "                 blocks_per_group=3,\n",
    "                 norm_type=\"bn\",\n",
    "                 resblock=InvertedResidual,\n",
    "                 expand_ratio=2,):\n",
    "        super(ResnetCNN, self).__init__()\n",
    "        self.depths = [input_channels] + depths\n",
    "        self.resblock = resblock\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.blocks_per_group = blocks_per_group\n",
    "        self.layers = []\n",
    "        self.norm_type = norm_type\n",
    "        self.num_layers = self.blocks_per_group*len(depths)\n",
    "        for i in range(len(depths)):\n",
    "            self.layers.append(self._make_layer(self.depths[i],\n",
    "                                                self.depths[i+1],\n",
    "                                                strides[i],\n",
    "                                                ))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.train()\n",
    "\n",
    "    def _make_layer(self, in_channels, depth, stride,):\n",
    "\n",
    "        blocks = [self.resblock(in_channels, depth,\n",
    "                                expand_ratio=self.expand_ratio,\n",
    "                                stride=stride,\n",
    "                                norm_type=self.norm_type,\n",
    "                                num_layers=self.num_layers,)]\n",
    "\n",
    "        for i in range(1, self.blocks_per_group):\n",
    "            blocks.append(self.resblock(depth, depth,\n",
    "                                        expand_ratio=self.expand_ratio,\n",
    "                                        stride=1,\n",
    "                                        norm_type=self.norm_type,\n",
    "                                        num_layers=self.num_layers,))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    @property\n",
    "    def local_layer_depth(self):\n",
    "        return self.depths[-2]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.layers(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ResnetCNN                                     [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-1                             [1, 64, 7, 7]             --\n",
       "│    └─Sequential: 2-1                        [1, 16, 28, 28]           --\n",
       "│    │    └─InvertedResidual: 3-1             [1, 16, 28, 28]           --\n",
       "│    │    │    └─Conv2d: 4-1                  [1, 16, 28, 28]           592\n",
       "│    │    │    └─Sequential: 4-2              [1, 16, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-1             [1, 8, 84, 84]            40\n",
       "│    │    │    │    └─BatchNorm2d: 5-2        [1, 8, 84, 84]            16\n",
       "│    │    │    │    └─ReLU: 5-3               [1, 8, 84, 84]            --\n",
       "│    │    │    │    └─Conv2d: 5-4             [1, 8, 28, 28]            80\n",
       "│    │    │    │    └─BatchNorm2d: 5-5        [1, 8, 28, 28]            16\n",
       "│    │    │    │    └─ReLU: 5-6               [1, 8, 28, 28]            --\n",
       "│    │    │    │    └─Conv2d: 5-7             [1, 16, 28, 28]           144\n",
       "│    │    │    │    └─BatchNorm2d: 5-8        [1, 16, 28, 28]           32\n",
       "│    │    └─InvertedResidual: 3-2             [1, 16, 28, 28]           --\n",
       "│    │    │    └─Sequential: 4-3              [1, 16, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-9             [1, 32, 28, 28]           544\n",
       "│    │    │    │    └─BatchNorm2d: 5-10       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-11              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-12            [1, 32, 28, 28]           320\n",
       "│    │    │    │    └─BatchNorm2d: 5-13       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-14              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-15            [1, 16, 28, 28]           528\n",
       "│    │    │    │    └─BatchNorm2d: 5-16       [1, 16, 28, 28]           32\n",
       "│    │    └─InvertedResidual: 3-3             [1, 16, 28, 28]           --\n",
       "│    │    │    └─Sequential: 4-4              [1, 16, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-17            [1, 32, 28, 28]           544\n",
       "│    │    │    │    └─BatchNorm2d: 5-18       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-19              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-20            [1, 32, 28, 28]           320\n",
       "│    │    │    │    └─BatchNorm2d: 5-21       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-22              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-23            [1, 16, 28, 28]           528\n",
       "│    │    │    │    └─BatchNorm2d: 5-24       [1, 16, 28, 28]           32\n",
       "│    └─Sequential: 2-2                        [1, 32, 14, 14]           --\n",
       "│    │    └─InvertedResidual: 3-4             [1, 32, 14, 14]           --\n",
       "│    │    │    └─Conv2d: 4-5                  [1, 32, 14, 14]           2,080\n",
       "│    │    │    └─Sequential: 4-6              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-25            [1, 32, 28, 28]           544\n",
       "│    │    │    │    └─BatchNorm2d: 5-26       [1, 32, 28, 28]           64\n",
       "│    │    │    │    └─ReLU: 5-27              [1, 32, 28, 28]           --\n",
       "│    │    │    │    └─Conv2d: 5-28            [1, 32, 14, 14]           320\n",
       "│    │    │    │    └─BatchNorm2d: 5-29       [1, 32, 14, 14]           64\n",
       "│    │    │    │    └─ReLU: 5-30              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-31            [1, 32, 14, 14]           1,056\n",
       "│    │    │    │    └─BatchNorm2d: 5-32       [1, 32, 14, 14]           64\n",
       "│    │    └─InvertedResidual: 3-5             [1, 32, 14, 14]           --\n",
       "│    │    │    └─Sequential: 4-7              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-33            [1, 64, 14, 14]           2,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-34       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-35              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-36            [1, 64, 14, 14]           640\n",
       "│    │    │    │    └─BatchNorm2d: 5-37       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-38              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-39            [1, 32, 14, 14]           2,080\n",
       "│    │    │    │    └─BatchNorm2d: 5-40       [1, 32, 14, 14]           64\n",
       "│    │    └─InvertedResidual: 3-6             [1, 32, 14, 14]           --\n",
       "│    │    │    └─Sequential: 4-8              [1, 32, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-41            [1, 64, 14, 14]           2,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-42       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-43              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-44            [1, 64, 14, 14]           640\n",
       "│    │    │    │    └─BatchNorm2d: 5-45       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-46              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-47            [1, 32, 14, 14]           2,080\n",
       "│    │    │    │    └─BatchNorm2d: 5-48       [1, 32, 14, 14]           64\n",
       "│    └─Sequential: 2-3                        [1, 64, 7, 7]             --\n",
       "│    │    └─InvertedResidual: 3-7             [1, 64, 7, 7]             --\n",
       "│    │    │    └─Conv2d: 4-9                  [1, 64, 7, 7]             8,256\n",
       "│    │    │    └─Sequential: 4-10             [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-49            [1, 64, 14, 14]           2,112\n",
       "│    │    │    │    └─BatchNorm2d: 5-50       [1, 64, 14, 14]           128\n",
       "│    │    │    │    └─ReLU: 5-51              [1, 64, 14, 14]           --\n",
       "│    │    │    │    └─Conv2d: 5-52            [1, 64, 7, 7]             640\n",
       "│    │    │    │    └─BatchNorm2d: 5-53       [1, 64, 7, 7]             128\n",
       "│    │    │    │    └─ReLU: 5-54              [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-55            [1, 64, 7, 7]             4,160\n",
       "│    │    │    │    └─BatchNorm2d: 5-56       [1, 64, 7, 7]             128\n",
       "│    │    └─InvertedResidual: 3-8             [1, 64, 7, 7]             --\n",
       "│    │    │    └─Sequential: 4-11             [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-57            [1, 128, 7, 7]            8,320\n",
       "│    │    │    │    └─BatchNorm2d: 5-58       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-59              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-60            [1, 128, 7, 7]            1,280\n",
       "│    │    │    │    └─BatchNorm2d: 5-61       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-62              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-63            [1, 64, 7, 7]             8,256\n",
       "│    │    │    │    └─BatchNorm2d: 5-64       [1, 64, 7, 7]             128\n",
       "│    │    └─InvertedResidual: 3-9             [1, 64, 7, 7]             --\n",
       "│    │    │    └─Sequential: 4-12             [1, 64, 7, 7]             --\n",
       "│    │    │    │    └─Conv2d: 5-65            [1, 128, 7, 7]            8,320\n",
       "│    │    │    │    └─BatchNorm2d: 5-66       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-67              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-68            [1, 128, 7, 7]            1,280\n",
       "│    │    │    │    └─BatchNorm2d: 5-69       [1, 128, 7, 7]            256\n",
       "│    │    │    │    └─ReLU: 5-70              [1, 128, 7, 7]            --\n",
       "│    │    │    │    └─Conv2d: 5-71            [1, 64, 7, 7]             8,256\n",
       "│    │    │    │    └─BatchNorm2d: 5-72       [1, 64, 7, 7]             128\n",
       "===============================================================================================\n",
       "Total params: 71,064\n",
       "Trainable params: 71,064\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.91\n",
       "===============================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 5.80\n",
       "Params size (MB): 0.28\n",
       "Estimated Total Size (MB): 6.19\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'WHW`\\xb7\\xa8Y\\xba=T\\rW4~4\\xb9_: [h\\x95e\\x929\\x10(\\xd6\"\\xee\\x84{}B\\xe4\\xd2\\xb3IL\\xc3\\xa0\\x19v\\x97t\\xba\\xde']\n",
      "Bad pipe message: %s [b'i\\xc5\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\xa2']\n",
      "Bad pipe message: %s [b\"\\xd6\\xd9\\x92\\x12\\xeb+t\\x1e\\x9b'\\x10!\\xde\\xc7\\t9\\xa6\\xbb Q\\x8b\\xf0,\\x91\\x145\\xc9\\x04\\x8a&\\x83y\\xfa\\x96^\\xc19\\xfcW\\xdcs/kp+\\xab\\xbb\\xe64\\x83!\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\"]\n",
      "Bad pipe message: %s [b'\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05']\n",
      "Bad pipe message: %s [b\"\\r\\x95\\xceHX\\x1b\\x1b\\xe3N2\\xf8\\x10-e\\x11A\\xef\\x7f\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\"]\n",
      "Bad pipe message: %s [b'\\x03\\x08']\n",
      "Bad pipe message: %s [b'\\x03\\x03']\n",
      "Bad pipe message: %s [b\"\\x1e \\xa9\\xac\\xd4\\x05e\\xde|\\x126\\xc9\\xa2\\x8a\\xd3\\x9by\\xca\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\"]\n",
      "Bad pipe message: %s [b'\\x08\\x08\\t\\x08\\n\\x08']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\xdc\\x9b\\x12\\xed7\\xa4}m\\x04\\x93i>6\\xaf\\xed\\xe3\\xf2H\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00', b'\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00']\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 QPpT@\\xec\\x05\\xecF\\xec\\x8eme\\xfcK\\xab\\xb0\\x1cn\\x1ei\\x98']\n",
      "Bad pipe message: %s [b'\\x8f\\xae\\xdd$\\x84\\x12t\\xe3\\xf0\\x81\\x9a9\\xf6\\xdc>\\xef\\x84/\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x00', b'\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004']\n",
      "Bad pipe message: %s [b'\\xddd\\x91\\xf4%;\\xe0*5\\x8a)\\xd22#\\xd6\\xd2\\x7f{\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00']\n",
      "Bad pipe message: %s [b'\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01']\n",
      "Bad pipe message: %s [b'\\x85\\x9d5\\xae\\x9dIAo\\x1b@\\x03\\x15\\xca\\x94\\xabJz\\xb4\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00', b'\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00']\n",
      "Bad pipe message: %s [b'\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06']\n",
      "Bad pipe message: %s [b'\\xbbF\\xf4\\xddB4<\\x05(\\x87\\xb4\\xa3\\xfbQ\\xfd\\x97@ \\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97']\n",
      "Bad pipe message: %s [b'T\\x92  \\xb8\\x11\\x86\\xffiT_\\xd15\\x83~)\\xcd\\xc3\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00', b'\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0']\n",
      "Bad pipe message: %s [b'\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00']\n",
      "Bad pipe message: %s [b\"\\xa1\\xb2\\x18\\x1d\\x91d\\x1c\\x81\\xe9\\xdf\\xfe\\x85.\\xabK\\xc7\\xbb\\x87\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\"]\n",
      "Bad pipe message: %s [b'\\xa4\\x177\\xa6:\\xba\\x86\\x85\\xa9\\x1a\\x15']\n",
      "Bad pipe message: %s [b'\\x06Q\\xd1\\xf8\\x15\\x00\\x00\\xf4\\xc00\\xc0,\\xc0']\n",
      "Bad pipe message: %s [b'$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19']\n"
     ]
    }
   ],
   "source": [
    "model = ResnetCNN(4, depths=[16, 32, 64], strides=(3, 2, 2), blocks_per_group=3, norm_type=\"bn\", resblock=InvertedResidual, expand_ratio=2,)\n",
    "model(torch.randn(1, 4, 84,84))\n",
    "torchinfo.summary(model, input_data=torch.randn(1, 4, 84,84), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0370,  0.2577, -0.6504,  ...,  0.8322,  0.0262,  0.4602],\n",
       "          [ 0.2142,  0.6859,  0.6797,  ..., -0.0790,  1.0790, -0.0139],\n",
       "          [-0.0260, -0.0173,  0.1069,  ...,  1.3578,  0.0800, -0.1256],\n",
       "          ...,\n",
       "          [-0.6908,  0.7027,  0.6468,  ...,  0.1948,  0.0255,  0.2132],\n",
       "          [ 0.6789, -0.8355, -0.4995,  ...,  0.8612, -0.7073,  1.1848],\n",
       "          [ 0.2609,  0.7734, -0.3453,  ..., -0.5624,  1.2338,  0.4828]],\n",
       "\n",
       "         [[ 0.2159,  0.9686, -1.3405,  ...,  0.1267,  0.6852, -0.7005],\n",
       "          [ 1.4288, -0.7463,  0.2360,  ...,  0.3765,  0.4661,  0.0409],\n",
       "          [ 0.0570,  0.3688,  0.7673,  ...,  1.0083, -1.6013, -0.2023],\n",
       "          ...,\n",
       "          [ 0.8709, -0.3425,  0.8199,  ..., -0.5406,  1.2382, -0.3373],\n",
       "          [-0.1634,  0.3192, -0.6712,  ...,  0.6687,  1.3732,  0.2786],\n",
       "          [-1.2140,  0.0601, -0.3932,  ...,  0.2761,  0.0425, -0.2627]],\n",
       "\n",
       "         [[ 0.4881,  1.1397, -0.1119,  ...,  0.5542,  0.1194,  0.3526],\n",
       "          [ 0.7851,  0.0861,  0.2837,  ...,  0.4316, -1.3768,  0.5899],\n",
       "          [ 0.6227,  0.9709,  0.6017,  ...,  0.2905,  1.1109, -0.3765],\n",
       "          ...,\n",
       "          [ 0.7780, -0.1938, -0.3952,  ..., -0.1347,  0.0191,  0.0976],\n",
       "          [ 0.1486, -0.3795,  0.1207,  ..., -0.7281, -0.3125,  0.0928],\n",
       "          [-0.4386,  1.2904,  0.4584,  ...,  0.4365,  0.3525,  0.8111]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3506, -0.8202, -0.2041,  ..., -0.4214, -0.1006, -0.4077],\n",
       "          [-0.1949, -0.3155, -1.0273,  ...,  0.3203,  0.7315,  0.4303],\n",
       "          [-0.0142, -0.2378, -0.7655,  ...,  1.2506,  0.1953, -0.2190],\n",
       "          ...,\n",
       "          [-0.3582,  0.2405, -0.0550,  ...,  0.1733,  0.0562, -1.1418],\n",
       "          [-0.7543, -0.7137, -0.9117,  ..., -0.7326, -0.0353,  0.8259],\n",
       "          [-0.2427,  1.2800, -0.4439,  ..., -0.5019,  0.4316, -0.0963]],\n",
       "\n",
       "         [[ 0.4719,  0.1515, -0.2211,  ...,  0.6594,  0.4770,  1.0572],\n",
       "          [ 1.1908,  0.3649,  0.8495,  ..., -0.6528, -0.8648,  0.6587],\n",
       "          [ 0.0134,  0.0622,  0.4296,  ...,  0.4145, -0.6186, -0.2118],\n",
       "          ...,\n",
       "          [ 0.2418,  0.5387,  0.3333,  ...,  0.7272, -0.7328,  0.6199],\n",
       "          [ 1.1811,  0.1222, -0.1965,  ...,  1.4675,  0.4542,  0.4096],\n",
       "          [ 0.7223, -0.3853,  0.8692,  ...,  0.4663,  1.3839,  0.5769]],\n",
       "\n",
       "         [[-0.2245, -0.6184, -0.6241,  ..., -0.0530,  0.2435,  0.9404],\n",
       "          [ 0.1478, -0.4637,  0.6067,  ...,  0.1467,  0.6257, -1.1542],\n",
       "          [ 0.6209,  0.2425, -0.3170,  ..., -0.9923,  1.4306, -0.3808],\n",
       "          ...,\n",
       "          [ 0.7266,  0.1540,  0.2181,  ..., -0.4048, -0.1952,  0.4127],\n",
       "          [ 0.9348, -0.4734, -1.2091,  ...,  0.6060, -0.1852,  0.0676],\n",
       "          [-1.9663,  0.2939, -0.0691,  ..., -0.6187,  1.7132, -1.1164]]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.models.ConvNeXt(\n",
    "        in_chans=4,\n",
    "        global_pool='avg',\n",
    "        output_stride= 32,\n",
    "        depths=(3, 3, 3, 0),\n",
    "        dims=(16, 32, 64, 64),\n",
    "        kernel_sizes=7,\n",
    "        stem_type='patch',\n",
    "        patch_size=3, # TODO calculate and make sure it is suitable\n",
    "        conv_mlp=False,\n",
    "        act_layer='gelu',\n",
    "        norm_layer=None,\n",
    "        drop_rate=0.0,\n",
    "        drop_path_rate=0.0,\n",
    "    )\n",
    "model.head.global_pool = nn.Identity()\n",
    "model.head.norm = nn.Identity()\n",
    "model.head.flatten = nn.Identity()\n",
    "model.head.fc = nn.Identity()\n",
    "model.head.dropout = nn.Identity()\n",
    "model.stages = model.stages[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ConvNeXt                                      [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-1                             [1, 16, 28, 28]           --\n",
       "│    └─Conv2d: 2-1                            [1, 16, 28, 28]           592\n",
       "│    └─LayerNorm2d: 2-2                       [1, 16, 28, 28]           32\n",
       "├─Sequential: 1-2                             [1, 64, 7, 7]             --\n",
       "│    └─ConvNeXtStage: 2-3                     [1, 16, 28, 28]           --\n",
       "│    │    └─Identity: 3-1                     [1, 16, 28, 28]           --\n",
       "│    │    └─Sequential: 3-2                   [1, 16, 28, 28]           --\n",
       "│    │    │    └─ConvNeXtBlock: 4-1           [1, 16, 28, 28]           16\n",
       "│    │    │    │    └─Conv2d: 5-1             [1, 16, 28, 28]           800\n",
       "│    │    │    │    └─LayerNorm: 5-2          [1, 28, 28, 16]           32\n",
       "│    │    │    │    └─Mlp: 5-3                [1, 28, 28, 16]           --\n",
       "│    │    │    │    │    └─Linear: 6-1        [1, 28, 28, 64]           1,088\n",
       "│    │    │    │    │    └─GELU: 6-2          [1, 28, 28, 64]           --\n",
       "│    │    │    │    │    └─Dropout: 6-3       [1, 28, 28, 64]           --\n",
       "│    │    │    │    │    └─Linear: 6-4        [1, 28, 28, 16]           1,040\n",
       "│    │    │    │    │    └─Dropout: 6-5       [1, 28, 28, 16]           --\n",
       "│    │    │    │    └─Identity: 5-4           [1, 16, 28, 28]           --\n",
       "│    │    │    └─ConvNeXtBlock: 4-2           [1, 16, 28, 28]           16\n",
       "│    │    │    │    └─Conv2d: 5-5             [1, 16, 28, 28]           800\n",
       "│    │    │    │    └─LayerNorm: 5-6          [1, 28, 28, 16]           32\n",
       "│    │    │    │    └─Mlp: 5-7                [1, 28, 28, 16]           --\n",
       "│    │    │    │    │    └─Linear: 6-6        [1, 28, 28, 64]           1,088\n",
       "│    │    │    │    │    └─GELU: 6-7          [1, 28, 28, 64]           --\n",
       "│    │    │    │    │    └─Dropout: 6-8       [1, 28, 28, 64]           --\n",
       "│    │    │    │    │    └─Linear: 6-9        [1, 28, 28, 16]           1,040\n",
       "│    │    │    │    │    └─Dropout: 6-10      [1, 28, 28, 16]           --\n",
       "│    │    │    │    └─Identity: 5-8           [1, 16, 28, 28]           --\n",
       "│    │    │    └─ConvNeXtBlock: 4-3           [1, 16, 28, 28]           16\n",
       "│    │    │    │    └─Conv2d: 5-9             [1, 16, 28, 28]           800\n",
       "│    │    │    │    └─LayerNorm: 5-10         [1, 28, 28, 16]           32\n",
       "│    │    │    │    └─Mlp: 5-11               [1, 28, 28, 16]           --\n",
       "│    │    │    │    │    └─Linear: 6-11       [1, 28, 28, 64]           1,088\n",
       "│    │    │    │    │    └─GELU: 6-12         [1, 28, 28, 64]           --\n",
       "│    │    │    │    │    └─Dropout: 6-13      [1, 28, 28, 64]           --\n",
       "│    │    │    │    │    └─Linear: 6-14       [1, 28, 28, 16]           1,040\n",
       "│    │    │    │    │    └─Dropout: 6-15      [1, 28, 28, 16]           --\n",
       "│    │    │    │    └─Identity: 5-12          [1, 16, 28, 28]           --\n",
       "│    └─ConvNeXtStage: 2-4                     [1, 32, 14, 14]           --\n",
       "│    │    └─Sequential: 3-3                   [1, 32, 14, 14]           --\n",
       "│    │    │    └─LayerNorm2d: 4-4             [1, 16, 28, 28]           32\n",
       "│    │    │    └─Conv2d: 4-5                  [1, 32, 14, 14]           2,080\n",
       "│    │    └─Sequential: 3-4                   [1, 32, 14, 14]           --\n",
       "│    │    │    └─ConvNeXtBlock: 4-6           [1, 32, 14, 14]           32\n",
       "│    │    │    │    └─Conv2d: 5-13            [1, 32, 14, 14]           1,600\n",
       "│    │    │    │    └─LayerNorm: 5-14         [1, 14, 14, 32]           64\n",
       "│    │    │    │    └─Mlp: 5-15               [1, 14, 14, 32]           --\n",
       "│    │    │    │    │    └─Linear: 6-16       [1, 14, 14, 128]          4,224\n",
       "│    │    │    │    │    └─GELU: 6-17         [1, 14, 14, 128]          --\n",
       "│    │    │    │    │    └─Dropout: 6-18      [1, 14, 14, 128]          --\n",
       "│    │    │    │    │    └─Linear: 6-19       [1, 14, 14, 32]           4,128\n",
       "│    │    │    │    │    └─Dropout: 6-20      [1, 14, 14, 32]           --\n",
       "│    │    │    │    └─Identity: 5-16          [1, 32, 14, 14]           --\n",
       "│    │    │    └─ConvNeXtBlock: 4-7           [1, 32, 14, 14]           32\n",
       "│    │    │    │    └─Conv2d: 5-17            [1, 32, 14, 14]           1,600\n",
       "│    │    │    │    └─LayerNorm: 5-18         [1, 14, 14, 32]           64\n",
       "│    │    │    │    └─Mlp: 5-19               [1, 14, 14, 32]           --\n",
       "│    │    │    │    │    └─Linear: 6-21       [1, 14, 14, 128]          4,224\n",
       "│    │    │    │    │    └─GELU: 6-22         [1, 14, 14, 128]          --\n",
       "│    │    │    │    │    └─Dropout: 6-23      [1, 14, 14, 128]          --\n",
       "│    │    │    │    │    └─Linear: 6-24       [1, 14, 14, 32]           4,128\n",
       "│    │    │    │    │    └─Dropout: 6-25      [1, 14, 14, 32]           --\n",
       "│    │    │    │    └─Identity: 5-20          [1, 32, 14, 14]           --\n",
       "│    │    │    └─ConvNeXtBlock: 4-8           [1, 32, 14, 14]           32\n",
       "│    │    │    │    └─Conv2d: 5-21            [1, 32, 14, 14]           1,600\n",
       "│    │    │    │    └─LayerNorm: 5-22         [1, 14, 14, 32]           64\n",
       "│    │    │    │    └─Mlp: 5-23               [1, 14, 14, 32]           --\n",
       "│    │    │    │    │    └─Linear: 6-26       [1, 14, 14, 128]          4,224\n",
       "│    │    │    │    │    └─GELU: 6-27         [1, 14, 14, 128]          --\n",
       "│    │    │    │    │    └─Dropout: 6-28      [1, 14, 14, 128]          --\n",
       "│    │    │    │    │    └─Linear: 6-29       [1, 14, 14, 32]           4,128\n",
       "│    │    │    │    │    └─Dropout: 6-30      [1, 14, 14, 32]           --\n",
       "│    │    │    │    └─Identity: 5-24          [1, 32, 14, 14]           --\n",
       "│    └─ConvNeXtStage: 2-5                     [1, 64, 7, 7]             --\n",
       "│    │    └─Sequential: 3-5                   [1, 64, 7, 7]             --\n",
       "│    │    │    └─LayerNorm2d: 4-9             [1, 32, 14, 14]           64\n",
       "│    │    │    └─Conv2d: 4-10                 [1, 64, 7, 7]             8,256\n",
       "│    │    └─Sequential: 3-6                   [1, 64, 7, 7]             --\n",
       "│    │    │    └─ConvNeXtBlock: 4-11          [1, 64, 7, 7]             64\n",
       "│    │    │    │    └─Conv2d: 5-25            [1, 64, 7, 7]             3,200\n",
       "│    │    │    │    └─LayerNorm: 5-26         [1, 7, 7, 64]             128\n",
       "│    │    │    │    └─Mlp: 5-27               [1, 7, 7, 64]             --\n",
       "│    │    │    │    │    └─Linear: 6-31       [1, 7, 7, 256]            16,640\n",
       "│    │    │    │    │    └─GELU: 6-32         [1, 7, 7, 256]            --\n",
       "│    │    │    │    │    └─Dropout: 6-33      [1, 7, 7, 256]            --\n",
       "│    │    │    │    │    └─Linear: 6-34       [1, 7, 7, 64]             16,448\n",
       "│    │    │    │    │    └─Dropout: 6-35      [1, 7, 7, 64]             --\n",
       "│    │    │    │    └─Identity: 5-28          [1, 64, 7, 7]             --\n",
       "│    │    │    └─ConvNeXtBlock: 4-12          [1, 64, 7, 7]             64\n",
       "│    │    │    │    └─Conv2d: 5-29            [1, 64, 7, 7]             3,200\n",
       "│    │    │    │    └─LayerNorm: 5-30         [1, 7, 7, 64]             128\n",
       "│    │    │    │    └─Mlp: 5-31               [1, 7, 7, 64]             --\n",
       "│    │    │    │    │    └─Linear: 6-36       [1, 7, 7, 256]            16,640\n",
       "│    │    │    │    │    └─GELU: 6-37         [1, 7, 7, 256]            --\n",
       "│    │    │    │    │    └─Dropout: 6-38      [1, 7, 7, 256]            --\n",
       "│    │    │    │    │    └─Linear: 6-39       [1, 7, 7, 64]             16,448\n",
       "│    │    │    │    │    └─Dropout: 6-40      [1, 7, 7, 64]             --\n",
       "│    │    │    │    └─Identity: 5-32          [1, 64, 7, 7]             --\n",
       "│    │    │    └─ConvNeXtBlock: 4-13          [1, 64, 7, 7]             64\n",
       "│    │    │    │    └─Conv2d: 5-33            [1, 64, 7, 7]             3,200\n",
       "│    │    │    │    └─LayerNorm: 5-34         [1, 7, 7, 64]             128\n",
       "│    │    │    │    └─Mlp: 5-35               [1, 7, 7, 64]             --\n",
       "│    │    │    │    │    └─Linear: 6-41       [1, 7, 7, 256]            16,640\n",
       "│    │    │    │    │    └─GELU: 6-42         [1, 7, 7, 256]            --\n",
       "│    │    │    │    │    └─Dropout: 6-43      [1, 7, 7, 256]            --\n",
       "│    │    │    │    │    └─Linear: 6-44       [1, 7, 7, 64]             16,448\n",
       "│    │    │    │    │    └─Dropout: 6-45      [1, 7, 7, 64]             --\n",
       "│    │    │    │    └─Identity: 5-36          [1, 64, 7, 7]             --\n",
       "├─Identity: 1-3                               [1, 64, 7, 7]             --\n",
       "├─Sequential: 1-4                             --                        --\n",
       "│    └─Identity: 2-6                          [1, 64, 7, 7]             --\n",
       "│    └─Identity: 2-7                          [1, 64, 7, 7]             --\n",
       "│    └─Identity: 2-8                          [1, 64, 7, 7]             --\n",
       "│    └─Dropout: 2-9                           [1, 64, 7, 7]             --\n",
       "│    └─Identity: 2-10                         [1, 64, 7, 7]             --\n",
       "===============================================================================================\n",
       "Total params: 159,568\n",
       "Trainable params: 159,568\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 4.70\n",
       "===============================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 4.11\n",
       "Params size (MB): 0.64\n",
       "Estimated Total Size (MB): 4.86\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, input_data=torch.randn(1, 4, 84,84), depth=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
